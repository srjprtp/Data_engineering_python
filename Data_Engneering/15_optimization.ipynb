{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc96d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config('spark.ui.port','0'). \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/itv020649/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4946737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://g01.itversity.com:38633\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe7af51c2e8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848c668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderDf = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".option(\"inferSchema\",\"true\") \\\n",
    ".option(\"header\",\"true\") \\\n",
    ".load(\"/public/trendytech/orders_wh/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3701147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+---------------+\n",
      "|order_id|          order_date|customer_id|   order_status|\n",
      "+--------+--------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:...|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:...|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:...|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:...|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:...|      11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:...|       7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:...|       4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:...|       2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:...|       5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:...|       5648|PENDING_PAYMENT|\n",
      "+--------+--------------------+-----------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orderDf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5efea949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orderDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d937fbe6",
   "metadata": {},
   "source": [
    "## Optimization session 1\n",
    "1. application code level\n",
    "cache, reducebykey > gropupby key, parquet\n",
    "2. cluster level optimization\n",
    "resource disturbution, containers/executers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42048ad8",
   "metadata": {},
   "source": [
    "### session 2\n",
    "resources - memory (RAM) , CPU cores (Compute)\n",
    "our intention to make sure job is getting right amount of resources\n",
    "\n",
    "10 node cluster (10 worker node)\n",
    "16 CPU core\n",
    "64 GB RAM\n",
    "\n",
    "Executor (container of resource)\n",
    "1 node > 1 executor(multiple container in one node)\n",
    "\n",
    "container/executor/JVM - cpu core  = memory(ram)\n",
    "\n",
    "16 core, 64 GB RAM - 1 core for backgroud processes, 15 core usable\n",
    "\n",
    "1. Thin executor - to create more executor with minimum possible executor.\n",
    "16 executor, with each holding 1 core and 4 GB RAM\n",
    "Drawback:-\n",
    "multi-threading not possible\n",
    "a lot of copy of broadcast variable required\n",
    "\n",
    "\n",
    "2. Fat executor - As big as possible\n",
    "1 executor : 16 core, 64 GB ram\n",
    "Draback:\n",
    "it is observed, if ececutor hold more than 5 core HDFS throughput suffers.\n",
    "if execotor holds very huge amount of memory, garbage collection take a lot time.\n",
    "garbage collection:removing objects from memory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3515fe08",
   "metadata": {},
   "source": [
    "### Session 3\n",
    "\n",
    "Right aproach balanced approach\n",
    "16 cores,64GB\n",
    "1gb OS\n",
    "1 core to demon process\n",
    "\n",
    "Cores >1 support multithreading, HDFS trouughput should not suffer cores<=5\n",
    "3 executor: each 5 cpu core and 21 GB\n",
    "out of 21 GB some of it will go to OFF heap(overhead)\n",
    "MAX(384, 7% of executor memory) = 1.5GB\n",
    "21-1.5 ~ 19 GB\n",
    "\n",
    "5 CPU core, 19 GB RAM\n",
    "10 node clustor/worker node\n",
    "10*3=30 30 executor\n",
    "\n",
    "1 Executor will be taken by YARN application manager\n",
    "10 nodes * 3 executor * 5 CPU Core = 150 tasks will run in parallel\n",
    "\n",
    "on-heap - memory inside executor\n",
    "Off-heap memory - outside executor   (objects created hear doesnot require Garbage collection but memory should be manageg programatically)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43427d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
