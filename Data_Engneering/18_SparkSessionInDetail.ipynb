{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc147ad",
   "metadata": {},
   "source": [
    "Spark session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb88dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1948d1",
   "metadata": {},
   "source": [
    "SparkSession. \\\n",
    "builder. \\\n",
    "appName(\"sapark session demo\"). \\\n",
    "config(\"spark.sql.warehouse.dir\",\"/user/itv020649/warehouse\"). \\#data is stored like managed spark table\n",
    "enableHiveSupport(). \\ # i should be able to assess hive meta store\n",
    "master('yarn'). \\ # or marter(local[*]) ,decides where the spark job should be running in hadoop cluster,it will check the config file and get url master\n",
    "getOrCreate() # one spark session per application, even if rinning two times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23dcd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "appName(\"sapark session demo\"). \\\n",
    "config(\"spark.sql.warehouse.dir\",\"/user/itv020649/warehouse\"). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "448c76c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7faa74fbe080>\n"
     ]
    }
   ],
   "source": [
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2970095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://g01.itversity.com:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sapark session demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7faa74fbe080>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark\n",
    "#with enableHiveSupport(). \\ the meta data is in SparkSession - hive without it  in-memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69fe865",
   "metadata": {},
   "source": [
    "what is need to saprk session if we have sparkContext?\n",
    "\n",
    ":unifies all different context\n",
    "    \n",
    "two isolated environment in application\n",
    "\n",
    "for use case to create 2 spark context within same application it was issue\n",
    "\n",
    "we can have more than one spark session in one application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47b91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparksession2 = spark.newSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73a03c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7faa74fcf550>\n"
     ]
    }
   ],
   "source": [
    "print(sparksession2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13398bb1",
   "metadata": {},
   "source": [
    "same spark context will be shared among different session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b1627a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderDf = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".option(\"inferSchema\",\"true\") \\\n",
    ".option(\"header\",\"true\") \\\n",
    ".load(\"/public/trendytech/orders_wh/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66fc175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+---------------+\n",
      "|order_id|          order_date|customer_id|   order_status|\n",
      "+--------+--------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:...|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:...|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:...|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:...|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:...|      11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:...|       7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:...|       4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:...|       2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:...|       5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:...|       5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:...|        918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:...|       1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:...|       9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:...|       9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:...|       2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:...|       7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:...|       2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:...|       1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:...|       9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:...|       9198|     PROCESSING|\n",
      "+--------+--------------------+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orderDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1be1edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderDf.createOrReplaceTempView(\"order_table1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5843dac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-----------+\n",
      "|database|   tableName|isTemporary|\n",
      "+--------+------------+-----------+\n",
      "|        | order_table|       true|\n",
      "|        |order_table1|       true|\n",
      "+--------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d943fc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparksession2.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "660b9bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderDf.createOrReplaceGlobalTempView(\"orderGlobal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bee4533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>order_id</th><th>order_date</th><th>customer_id</th><th>order_status</th></tr>\n",
       "<tr><td>1</td><td>2013-07-25 00:00:...</td><td>11599</td><td>CLOSED</td></tr>\n",
       "<tr><td>2</td><td>2013-07-25 00:00:...</td><td>256</td><td>PENDING_PAYMENT</td></tr>\n",
       "<tr><td>3</td><td>2013-07-25 00:00:...</td><td>12111</td><td>COMPLETE</td></tr>\n",
       "<tr><td>4</td><td>2013-07-25 00:00:...</td><td>8827</td><td>CLOSED</td></tr>\n",
       "<tr><td>5</td><td>2013-07-25 00:00:...</td><td>11318</td><td>COMPLETE</td></tr>\n",
       "<tr><td>6</td><td>2013-07-25 00:00:...</td><td>7130</td><td>COMPLETE</td></tr>\n",
       "<tr><td>7</td><td>2013-07-25 00:00:...</td><td>4530</td><td>COMPLETE</td></tr>\n",
       "<tr><td>8</td><td>2013-07-25 00:00:...</td><td>2911</td><td>PROCESSING</td></tr>\n",
       "<tr><td>9</td><td>2013-07-25 00:00:...</td><td>5657</td><td>PENDING_PAYMENT</td></tr>\n",
       "<tr><td>10</td><td>2013-07-25 00:00:...</td><td>5648</td><td>PENDING_PAYMENT</td></tr>\n",
       "<tr><td>11</td><td>2013-07-25 00:00:...</td><td>918</td><td>PAYMENT_REVIEW</td></tr>\n",
       "<tr><td>12</td><td>2013-07-25 00:00:...</td><td>1837</td><td>CLOSED</td></tr>\n",
       "<tr><td>13</td><td>2013-07-25 00:00:...</td><td>9149</td><td>PENDING_PAYMENT</td></tr>\n",
       "<tr><td>14</td><td>2013-07-25 00:00:...</td><td>9842</td><td>PROCESSING</td></tr>\n",
       "<tr><td>15</td><td>2013-07-25 00:00:...</td><td>2568</td><td>COMPLETE</td></tr>\n",
       "<tr><td>16</td><td>2013-07-25 00:00:...</td><td>7276</td><td>PENDING_PAYMENT</td></tr>\n",
       "<tr><td>17</td><td>2013-07-25 00:00:...</td><td>2667</td><td>COMPLETE</td></tr>\n",
       "<tr><td>18</td><td>2013-07-25 00:00:...</td><td>1205</td><td>CLOSED</td></tr>\n",
       "<tr><td>19</td><td>2013-07-25 00:00:...</td><td>9488</td><td>PENDING_PAYMENT</td></tr>\n",
       "<tr><td>20</td><td>2013-07-25 00:00:...</td><td>9198</td><td>PROCESSING</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------+--------------------+-----------+---------------+\n",
       "|order_id|          order_date|customer_id|   order_status|\n",
       "+--------+--------------------+-----------+---------------+\n",
       "|       1|2013-07-25 00:00:...|      11599|         CLOSED|\n",
       "|       2|2013-07-25 00:00:...|        256|PENDING_PAYMENT|\n",
       "|       3|2013-07-25 00:00:...|      12111|       COMPLETE|\n",
       "|       4|2013-07-25 00:00:...|       8827|         CLOSED|\n",
       "|       5|2013-07-25 00:00:...|      11318|       COMPLETE|\n",
       "|       6|2013-07-25 00:00:...|       7130|       COMPLETE|\n",
       "|       7|2013-07-25 00:00:...|       4530|       COMPLETE|\n",
       "|       8|2013-07-25 00:00:...|       2911|     PROCESSING|\n",
       "|       9|2013-07-25 00:00:...|       5657|PENDING_PAYMENT|\n",
       "|      10|2013-07-25 00:00:...|       5648|PENDING_PAYMENT|\n",
       "|      11|2013-07-25 00:00:...|        918| PAYMENT_REVIEW|\n",
       "|      12|2013-07-25 00:00:...|       1837|         CLOSED|\n",
       "|      13|2013-07-25 00:00:...|       9149|PENDING_PAYMENT|\n",
       "|      14|2013-07-25 00:00:...|       9842|     PROCESSING|\n",
       "|      15|2013-07-25 00:00:...|       2568|       COMPLETE|\n",
       "|      16|2013-07-25 00:00:...|       7276|PENDING_PAYMENT|\n",
       "|      17|2013-07-25 00:00:...|       2667|       COMPLETE|\n",
       "|      18|2013-07-25 00:00:...|       1205|         CLOSED|\n",
       "|      19|2013-07-25 00:00:...|       9488|PENDING_PAYMENT|\n",
       "|      20|2013-07-25 00:00:...|       9198|     PROCESSING|\n",
       "+--------+--------------------+-----------+---------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from global_temp.orderGlobal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bbc28d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>order_id</th><th>order_date</th><th>customer_id</th><th>order_status</th></tr>\n",
       "<tr><td>1</td><td>2013-07-25 00:00:...</td><td>11599</td><td>CLOSED</td></tr>\n",
       "<tr><td>2</td><td>2013-07-25 00:00:...</td><td>256</td><td>PENDING_PAYMENT</td></tr>\n",
       "<tr><td>3</td><td>2013-07-25 00:00:...</td><td>12111</td><td>COMPLETE</td></tr>\n",
       "<tr><td>4</td><td>2013-07-25 00:00:...</td><td>8827</td><td>CLOSED</td></tr>\n",
       "<tr><td>5</td><td>2013-07-25 00:00:...</td><td>11318</td><td>COMPLETE</td></tr>\n",
       "<tr><td>6</td><td>2013-07-25 00:00:...</td><td>7130</td><td>COMPLETE</td></tr>\n",
       "<tr><td>7</td><td>2013-07-25 00:00:...</td><td>4530</td><td>COMPLETE</td></tr>\n",
       "<tr><td>8</td><td>2013-07-25 00:00:...</td><td>2911</td><td>PROCESSING</td></tr>\n",
       "<tr><td>9</td><td>2013-07-25 00:00:...</td><td>5657</td><td>PENDING_PAYMENT</td></tr>\n",
       "<tr><td>10</td><td>2013-07-25 00:00:...</td><td>5648</td><td>PENDING_PAYMENT</td></tr>\n",
       "<tr><td>11</td><td>2013-07-25 00:00:...</td><td>918</td><td>PAYMENT_REVIEW</td></tr>\n",
       "<tr><td>12</td><td>2013-07-25 00:00:...</td><td>1837</td><td>CLOSED</td></tr>\n",
       "<tr><td>13</td><td>2013-07-25 00:00:...</td><td>9149</td><td>PENDING_PAYMENT</td></tr>\n",
       "<tr><td>14</td><td>2013-07-25 00:00:...</td><td>9842</td><td>PROCESSING</td></tr>\n",
       "<tr><td>15</td><td>2013-07-25 00:00:...</td><td>2568</td><td>COMPLETE</td></tr>\n",
       "<tr><td>16</td><td>2013-07-25 00:00:...</td><td>7276</td><td>PENDING_PAYMENT</td></tr>\n",
       "<tr><td>17</td><td>2013-07-25 00:00:...</td><td>2667</td><td>COMPLETE</td></tr>\n",
       "<tr><td>18</td><td>2013-07-25 00:00:...</td><td>1205</td><td>CLOSED</td></tr>\n",
       "<tr><td>19</td><td>2013-07-25 00:00:...</td><td>9488</td><td>PENDING_PAYMENT</td></tr>\n",
       "<tr><td>20</td><td>2013-07-25 00:00:...</td><td>9198</td><td>PROCESSING</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------+--------------------+-----------+---------------+\n",
       "|order_id|          order_date|customer_id|   order_status|\n",
       "+--------+--------------------+-----------+---------------+\n",
       "|       1|2013-07-25 00:00:...|      11599|         CLOSED|\n",
       "|       2|2013-07-25 00:00:...|        256|PENDING_PAYMENT|\n",
       "|       3|2013-07-25 00:00:...|      12111|       COMPLETE|\n",
       "|       4|2013-07-25 00:00:...|       8827|         CLOSED|\n",
       "|       5|2013-07-25 00:00:...|      11318|       COMPLETE|\n",
       "|       6|2013-07-25 00:00:...|       7130|       COMPLETE|\n",
       "|       7|2013-07-25 00:00:...|       4530|       COMPLETE|\n",
       "|       8|2013-07-25 00:00:...|       2911|     PROCESSING|\n",
       "|       9|2013-07-25 00:00:...|       5657|PENDING_PAYMENT|\n",
       "|      10|2013-07-25 00:00:...|       5648|PENDING_PAYMENT|\n",
       "|      11|2013-07-25 00:00:...|        918| PAYMENT_REVIEW|\n",
       "|      12|2013-07-25 00:00:...|       1837|         CLOSED|\n",
       "|      13|2013-07-25 00:00:...|       9149|PENDING_PAYMENT|\n",
       "|      14|2013-07-25 00:00:...|       9842|     PROCESSING|\n",
       "|      15|2013-07-25 00:00:...|       2568|       COMPLETE|\n",
       "|      16|2013-07-25 00:00:...|       7276|PENDING_PAYMENT|\n",
       "|      17|2013-07-25 00:00:...|       2667|       COMPLETE|\n",
       "|      18|2013-07-25 00:00:...|       1205|         CLOSED|\n",
       "|      19|2013-07-25 00:00:...|       9488|PENDING_PAYMENT|\n",
       "|      20|2013-07-25 00:00:...|       9198|     PROCESSING|\n",
       "+--------+--------------------+-----------+---------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparksession2.sql(\"select * from global_temp.orderGlobal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e826c598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop table order_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d7fad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-----------+\n",
      "|database|   tableName|isTemporary|\n",
      "+--------+------------+-----------+\n",
      "|        |order_table1|       true|\n",
      "+--------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce0bf3",
   "metadata": {},
   "source": [
    "#deploy mode\n",
    "per spark session app\n",
    "\n",
    "we have a driver - master \n",
    "\n",
    "and multiple executors - workers \n",
    "\n",
    "ex: 1 driver 20 executor, 1 driver 3 ex\n",
    "\n",
    "driver down app down\n",
    "\n",
    "1. Client mode - driver at client machine (gateway mode) - not for prod\n",
    "2. Cluster mode - in which your driver run in cluster(one of the executor)- for prod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d6a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
